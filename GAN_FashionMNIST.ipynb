{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAN_FashionMNIST.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWVZ8hsE-DGi",
        "colab_type": "text"
      },
      "source": [
        "# GAN on Fashion MNIST\n",
        "This notebook applies a GAN model to create other fashion image from the fashion MNIST dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOxH0RnIxoIn",
        "colab_type": "text"
      },
      "source": [
        "### Install required packages\n",
        "\n",
        "It is recommended to install the following packages: keras==2.1.2, keras_adversarial.\n",
        "Examples on how to install these dependencies are below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jv5GnCIR4yj0",
        "colab_type": "code",
        "outputId": "8ccb7230-e013-4956-bc52-26654c21d07d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        }
      },
      "source": [
        "!pip install --force-reinstall keras==2.1.2 #install keras compatible with keras_adversarial"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras==2.1.2\n",
            "  Using cached https://files.pythonhosted.org/packages/68/89/58ee5f56a9c26957d97217db41780ebedca3154392cb903c3f8a08a52208/Keras-2.1.2-py2.py3-none-any.whl\n",
            "Collecting scipy>=0.14 (from keras==2.1.2)\n",
            "  Using cached https://files.pythonhosted.org/packages/29/50/a552a5aff252ae915f522e44642bb49a7b7b31677f9580cfd11bcc869976/scipy-1.3.1-cp36-cp36m-manylinux1_x86_64.whl\n",
            "Collecting numpy>=1.9.1 (from keras==2.1.2)\n",
            "  Using cached https://files.pythonhosted.org/packages/e5/e6/c3fdc53aed9fa19d6ff3abf97dfad768ae3afce1b7431f7500000816bda5/numpy-1.17.2-cp36-cp36m-manylinux1_x86_64.whl\n",
            "Collecting pyyaml (from keras==2.1.2)\n",
            "Collecting six>=1.9.0 (from keras==2.1.2)\n",
            "  Using cached https://files.pythonhosted.org/packages/73/fb/00a976f728d0d1fecfe898238ce23f502a721c0ac0ecfedb80e0d88c64e9/six-1.12.0-py2.py3-none-any.whl\n",
            "\u001b[31mERROR: textgenrnn 1.4.1 has requirement keras>=2.1.5, but you'll have keras 2.1.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: numpy, scipy, pyyaml, six, keras\n",
            "  Found existing installation: numpy 1.17.2\n",
            "    Uninstalling numpy-1.17.2:\n",
            "      Successfully uninstalled numpy-1.17.2\n",
            "  Found existing installation: scipy 1.3.1\n",
            "    Uninstalling scipy-1.3.1:\n",
            "      Successfully uninstalled scipy-1.3.1\n",
            "  Found existing installation: PyYAML 5.1.2\n",
            "    Uninstalling PyYAML-5.1.2:\n",
            "      Successfully uninstalled PyYAML-5.1.2\n",
            "  Found existing installation: six 1.12.0\n",
            "    Uninstalling six-1.12.0:\n",
            "      Successfully uninstalled six-1.12.0\n",
            "  Found existing installation: Keras 2.1.2\n",
            "    Uninstalling Keras-2.1.2:\n",
            "      Successfully uninstalled Keras-2.1.2\n",
            "Successfully installed keras-2.1.2 numpy-1.17.2 pyyaml-5.1.2 scipy-1.3.1 six-1.12.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "six"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlCFg-ptw54u",
        "colab_type": "code",
        "outputId": "af4e5b4a-6fa9-478f-a336-925efd6dc0ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!git clone https://github.com/bstriner/keras_adversarial.git #clone keras_adversarial"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'keras_adversarial' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjAcQYIn4ICp",
        "colab_type": "code",
        "outputId": "44007558-020f-4b40-8f7b-c5fbfa2a81fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!cd keras_adversarial && python setup.py install #install keras_adversarial\n",
        "#you may restart the runtime "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "running install\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "writing keras_adversarial.egg-info/PKG-INFO\n",
            "writing dependency_links to keras_adversarial.egg-info/dependency_links.txt\n",
            "writing requirements to keras_adversarial.egg-info/requires.txt\n",
            "writing top-level names to keras_adversarial.egg-info/top_level.txt\n",
            "writing manifest file 'keras_adversarial.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_py\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/keras_adversarial\n",
            "copying build/lib/keras_adversarial/adversarial_model.py -> build/bdist.linux-x86_64/egg/keras_adversarial\n",
            "copying build/lib/keras_adversarial/legacy.py -> build/bdist.linux-x86_64/egg/keras_adversarial\n",
            "creating build/bdist.linux-x86_64/egg/keras_adversarial/backend\n",
            "copying build/lib/keras_adversarial/backend/theano_backend.py -> build/bdist.linux-x86_64/egg/keras_adversarial/backend\n",
            "copying build/lib/keras_adversarial/backend/tensorflow_monkeypatch.py -> build/bdist.linux-x86_64/egg/keras_adversarial/backend\n",
            "copying build/lib/keras_adversarial/backend/__init__.py -> build/bdist.linux-x86_64/egg/keras_adversarial/backend\n",
            "copying build/lib/keras_adversarial/backend/tensorflow_backend.py -> build/bdist.linux-x86_64/egg/keras_adversarial/backend\n",
            "copying build/lib/keras_adversarial/__init__.py -> build/bdist.linux-x86_64/egg/keras_adversarial\n",
            "copying build/lib/keras_adversarial/image_grid_callback.py -> build/bdist.linux-x86_64/egg/keras_adversarial\n",
            "copying build/lib/keras_adversarial/adversarial_utils.py -> build/bdist.linux-x86_64/egg/keras_adversarial\n",
            "copying build/lib/keras_adversarial/adversarial_optimizers.py -> build/bdist.linux-x86_64/egg/keras_adversarial\n",
            "copying build/lib/keras_adversarial/unrolled_optimizer.py -> build/bdist.linux-x86_64/egg/keras_adversarial\n",
            "copying build/lib/keras_adversarial/image_grid.py -> build/bdist.linux-x86_64/egg/keras_adversarial\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_adversarial/adversarial_model.py to adversarial_model.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_adversarial/legacy.py to legacy.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_adversarial/backend/theano_backend.py to theano_backend.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_adversarial/backend/tensorflow_monkeypatch.py to tensorflow_monkeypatch.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_adversarial/backend/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_adversarial/backend/tensorflow_backend.py to tensorflow_backend.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_adversarial/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_adversarial/image_grid_callback.py to image_grid_callback.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_adversarial/adversarial_utils.py to adversarial_utils.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_adversarial/adversarial_optimizers.py to adversarial_optimizers.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_adversarial/unrolled_optimizer.py to unrolled_optimizer.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_adversarial/image_grid.py to image_grid.cpython-36.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying keras_adversarial.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying keras_adversarial.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying keras_adversarial.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying keras_adversarial.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying keras_adversarial.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "creating 'dist/keras_adversarial-0.0.3-py3.6.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing keras_adversarial-0.0.3-py3.6.egg\n",
            "Removing /usr/local/lib/python3.6/dist-packages/keras_adversarial-0.0.3-py3.6.egg\n",
            "Copying keras_adversarial-0.0.3-py3.6.egg to /usr/local/lib/python3.6/dist-packages\n",
            "keras-adversarial 0.0.3 is already the active version in easy-install.pth\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/keras_adversarial-0.0.3-py3.6.egg\n",
            "Processing dependencies for keras-adversarial==0.0.3\n",
            "Searching for Keras==2.1.2\n",
            "Best match: Keras 2.1.2\n",
            "Adding Keras 2.1.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for PyYAML==5.1.2\n",
            "Best match: PyYAML 5.1.2\n",
            "Adding PyYAML 5.1.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for scipy==1.3.1\n",
            "Best match: scipy 1.3.1\n",
            "Adding scipy 1.3.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for numpy==1.17.2\n",
            "Best match: numpy 1.17.2\n",
            "Adding numpy 1.17.2 to easy-install.pth file\n",
            "Installing f2py script to /usr/local/bin\n",
            "Installing f2py3 script to /usr/local/bin\n",
            "Installing f2py3.6 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for six==1.12.0\n",
            "Best match: six 1.12.0\n",
            "Adding six 1.12.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Finished processing dependencies for keras-adversarial==0.0.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ORpt3XIxhSm",
        "colab_type": "text"
      },
      "source": [
        "### Import packages:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZaN39aCxHUd",
        "colab_type": "code",
        "outputId": "e182d016-40f3-4fc4-b5b0-604b417f26b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        }
      },
      "source": [
        "import pandas as pd # for data handling\n",
        "import numpy as np # for linear algebra\n",
        "import matplotlib.pyplot as plt #for visualisation\n",
        "import keras #for neural networks"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Anyo9PnqxK9S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#for neural networks\n",
        "from keras_adversarial import AdversarialModel, simple_gan, gan_targets\n",
        "from keras_adversarial import normal_latent_sampling, AdversarialOptimizerSimultaneous\n",
        "from keras_adversarial.legacy import fit\n",
        "import keras.backend as K\n",
        "from keras.layers import Conv2D, Flatten, Activation, Dense, UpSampling2D, Reshape, BatchNormalization, AveragePooling2D\n",
        "from keras.layers import BatchNormalization, Dropout\n",
        "from keras.optimizers import Adam\n",
        "from keras.initializers import TruncatedNormal\n",
        "from keras.models import Sequential\n",
        "from keras_adversarial.image_grid_callback import ImageGridCallback"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nOiodxLBx0r4",
        "colab_type": "text"
      },
      "source": [
        "### Prepare data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPeLy-Cg0VPf",
        "colab_type": "code",
        "outputId": "a5fe3334-56e2-455c-871b-93d0a125e13e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# get fashion mnist data\n",
        "(x_train,y_train), (x_test,y_test) = keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "# show shapes of tensors\n",
        "print(\"x_train shape:\", x_train.shape, \", y_train shape:\", y_train.shape)\n",
        "print(\"x_test shape:\", x_test.shape, \", y_test shape:\", y_test.shape)\n",
        "\n",
        "# get number of classes\n",
        "nClasses = len(np.unique(y_train)) # number of output classes\n",
        "print(\"Number of classes: \", nClasses)\n",
        "\n",
        "# normalize grayscale pixel values (0-255) to (0,1)\n",
        "x_train = x_train.astype('float32')/255 # normalized training inputs\n",
        "x_test = x_test.astype('float32')/255 # normalized test inputs\n",
        "\n",
        "# show shapes of re-shaped tensors\n",
        "print(\"x_train shape:\", x_train.shape, \", y_train shape:\", y_train.shape)\n",
        "print(\"x_test shape:\", x_test.shape, \", y_test shape:\", y_test.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (60000, 28, 28) , y_train shape: (60000,)\n",
            "x_test shape: (10000, 28, 28) , y_test shape: (10000,)\n",
            "Number of classes:  10\n",
            "x_train shape: (60000, 28, 28) , y_train shape: (60000,)\n",
            "x_test shape: (10000, 28, 28) , y_test shape: (10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNHoORB_0bzr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "latent_dim = 100 #dimention of the output "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJ0AlTGbxdCx",
        "colab_type": "text"
      },
      "source": [
        "### Build generator model: Dense-Conv1-Conv2-Conv3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSl2Qcm80gDv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_generator():\n",
        "    model_g = keras.Sequential([\n",
        "        #first fully connected\n",
        "        Dense(3136,  input_shape=(100,), kernel_initializer=TruncatedNormal(stddev=0.02), bias_initializer=TruncatedNormal(stddev=0.02)),\n",
        "        BatchNormalization(epsilon=1e-5),\n",
        "        Activation('relu'),\n",
        "        Reshape([56, 56, 1]),\n",
        "\n",
        "        #convolutional layer 1\n",
        "        Conv2D(50, kernel_size = (3,3), strides=(2, 2), kernel_initializer=TruncatedNormal(stddev=0.02),bias_initializer=TruncatedNormal(stddev=0.02),  padding=\"same\"),\n",
        "        BatchNormalization(epsilon=1e-5),\n",
        "        Activation('relu'),\n",
        "        UpSampling2D(size=(2, 2)),\n",
        "\n",
        "        #convolutional layer 2\n",
        "        Conv2D(25, kernel_size = (3,3), strides=(2, 2), kernel_initializer=TruncatedNormal(stddev=0.02),bias_initializer=TruncatedNormal(stddev=0.02),  padding=\"same\"),\n",
        "        BatchNormalization(epsilon=1e-5),\n",
        "        Activation('relu'),\n",
        "        UpSampling2D(size=(2, 2)),\n",
        "\n",
        "        #convolutional layer 3\n",
        "        Conv2D(1, kernel_size=(1,1), strides=(2, 2), padding=\"same\", kernel_initializer=TruncatedNormal(stddev=0.02), bias_initializer=TruncatedNormal(stddev=0.02), activation =\"sigmoid\")],\n",
        "        name=\"generator\")\n",
        "    return model_g\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtgHwCS50U5q",
        "colab_type": "text"
      },
      "source": [
        "### Build discriminator model with batch normalization: Conv1-Conv2-Dense1-Dense2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMgJVLA70hNb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_discriminator():\n",
        "    model_d = keras.Sequential([\n",
        "        #convolutional layer 1\n",
        "        Conv2D(32, kernel_size = (5,5), strides=(1, 1), kernel_initializer=TruncatedNormal(stddev=0.02), padding=\"same\", input_shape=(28, 28, 1)),\n",
        "        BatchNormalization(epsilon=1e-5),\n",
        "        Activation('relu'),\n",
        "        AveragePooling2D(pool_size=(2, 2), strides=(2, 2), padding=\"same\"),\n",
        "        \n",
        "        #convolutional layer 2\n",
        "        Conv2D(64, kernel_size = (5,5), strides=(1, 1), kernel_initializer=TruncatedNormal(stddev=0.02), padding=\"same\"),\n",
        "        BatchNormalization(epsilon=1e-5),\n",
        "        Activation('relu'),\n",
        "        AveragePooling2D(pool_size=(2, 2), strides=(2, 2), padding=\"same\"),\n",
        "        \n",
        "        #first fully connected\n",
        "        Flatten(),\n",
        "        Dense(1024,  kernel_initializer=TruncatedNormal(stddev=0.02)),\n",
        "        Activation('relu'),\n",
        "        \n",
        "        #second fully connected\n",
        "        Dense(1, kernel_initializer=TruncatedNormal(stddev=0.02)),\n",
        "        Activation('sigmoid')],\n",
        "        name=\"discriminator\")\n",
        "    return model_d\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDUmZUFF0kaG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generator_sampler(latent_dim, generator): #data sampling for generator inputs\n",
        "    def fun():\n",
        "        zsamples = np.random.normal(0, 1, size=(10 * 10, latent_dim)) #sample data from normal distribution with mean 0 and standard deviation 1\n",
        "        gen = dim_ordering_unfix(generator.predict(zsamples))\n",
        "        return gen.reshape((10, 10, 28, 28))\n",
        "\n",
        "    return fun"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3fQBjpK0neB",
        "colab_type": "code",
        "outputId": "bfc56e56-17d1-4d2f-aff7-1ba9c99d64d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        }
      },
      "source": [
        "# generator (z -> x)\n",
        "generator = model_generator()\n",
        "# discriminator (x -> y)\n",
        "discriminator = model_discriminator()\n",
        "gan = simple_gan(generator, discriminator, normal_latent_sampling((latent_dim,)))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:64: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:497: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3683: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1827: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3468: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1264: calling reduce_prod_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "keep_dims is deprecated, use keepdims instead\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3613: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUvenJ7x0pud",
        "colab_type": "code",
        "outputId": "bc3cea41-7afc-4c14-f170-e516cf6c8454",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#NNs' architecture\n",
        "generator.summary()\n",
        "discriminator.summary()\n",
        "gan.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 3136)              316736    \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 3136)              12544     \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 3136)              0         \n",
            "_________________________________________________________________\n",
            "reshape_1 (Reshape)          (None, 56, 56, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 28, 28, 50)        500       \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 28, 28, 50)        200       \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 28, 28, 50)        0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2 (None, 56, 56, 50)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 28, 28, 25)        11275     \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 28, 28, 25)        100       \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 28, 28, 25)        0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_2 (UpSampling2 (None, 56, 56, 25)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 28, 28, 1)         26        \n",
            "=================================================================\n",
            "Total params: 341,381\n",
            "Trainable params: 334,959\n",
            "Non-trainable params: 6,422\n",
            "_________________________________________________________________\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_4 (Conv2D)            (None, 28, 28, 32)        832       \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 28, 28, 32)        128       \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 28, 28, 32)        0         \n",
            "_________________________________________________________________\n",
            "average_pooling2d_1 (Average (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 14, 14, 64)        51264     \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 14, 14, 64)        256       \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "average_pooling2d_2 (Average (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 3136)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1024)              3212288   \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 1025      \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 3,265,793\n",
            "Trainable params: 3,265,601\n",
            "Non-trainable params: 192\n",
            "_________________________________________________________________\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "conv2d_4_input (InputLayer)     (None, 28, 28, 1)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lambda_1 (Lambda)               (None, 100)          0           conv2d_4_input[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "gan (Model)                     [(None, 1), (None, 1 3607174     lambda_1[0][0]                   \n",
            "                                                                 conv2d_4_input[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "yfake (Activation)              (None, 1)            0           gan[1][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "yreal (Activation)              (None, 1)            0           gan[1][1]                        \n",
            "==================================================================================================\n",
            "Total params: 3,607,174\n",
            "Trainable params: 3,600,560\n",
            "Non-trainable params: 6,614\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBJEmxIn0sKN",
        "colab_type": "code",
        "outputId": "dbeb9402-46f9-483e-f75f-62ac5a95872d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "model = AdversarialModel(base_model=gan, #build the model\n",
        "                             player_params=[generator.trainable_weights, discriminator.trainable_weights],\n",
        "                             player_names=[\"generator\", \"discriminator\"])\n",
        "model.adversarial_compile(adversarial_optimizer=AdversarialOptimizerSimultaneous(), #compile the model\n",
        "                              player_optimizers=[Adam(0.0003, decay=1e-4), Adam(0.0003, decay=1e-4)],\n",
        "                              loss='binary_crossentropy')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:711: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2950: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUk5Ojcz17A5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generator_cb = ImageGridCallback(\"output/gan_convolutional/epoch-{:03d}.png\",\n",
        "                                     generator_sampler(latent_dim, generator)) #save the output after each epoch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-6_HBBx2JFo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#for the image dimension ordering convention  \n",
        "def dim_ordering_fix(x):\n",
        "    if K.image_dim_ordering() == 'th':\n",
        "        return x\n",
        "    else:\n",
        "        return np.transpose(x, (0, 2, 3, 1))\n",
        "    \n",
        "def dim_ordering_unfix(x):\n",
        "    if K.image_dim_ordering() == 'th':\n",
        "        return x\n",
        "    else:\n",
        "        return np.transpose(x, (0, 3, 1, 2))\n",
        "      \n",
        "def dim_ordering_shape(input_shape):\n",
        "    if K.image_dim_ordering() == 'th':\n",
        "        return input_shape\n",
        "    else:\n",
        "        return (input_shape[1], input_shape[2], input_shape[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Rce8ln_j34vL",
        "colab": {}
      },
      "source": [
        "xtrain = dim_ordering_fix(x_train.reshape((-1, 1, 28, 28)))\n",
        "xtest = dim_ordering_fix(x_test.reshape((-1, 1, 28, 28)))\n",
        "y = gan_targets(xtrain.shape[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uT9t4DZD5eiS",
        "colab_type": "code",
        "outputId": "b93f5adc-d3d1-4c8f-e85d-6662be9f0209",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        }
      },
      "source": [
        "%time\n",
        "ytest = gan_targets(xtest.shape[0])\n",
        "history = model.fit(x=xtrain, y=y, validation_data=(xtest, ytest), callbacks=[generator_cb], nb_epoch=5,\n",
        "                        batch_size=100) #training the DCGAN\n",
        "df = pd.DataFrame(history.history) #convert to dataframe\n",
        "df.to_csv(\"output/gan_convolutional/history.csv\") #save the loss history "
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 4 µs, sys: 1 µs, total: 5 µs\n",
            "Wall time: 9.78 µs\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/5\n",
            "\r  100/60000 [..............................] - ETA: 1:07 - loss: 11.0530 - generator_loss: 11.0232 - generator_yfake_loss: 5.3271 - generator_yreal_loss: 5.6961 - discriminator_loss: 0.0298 - discriminator_yfake_loss: 0.0128 - discriminator_yreal_loss: 0.0170"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 66s 1ms/step - loss: 10.5978 - generator_loss: 10.4289 - generator_yfake_loss: 4.9500 - generator_yreal_loss: 5.4789 - discriminator_loss: 0.1689 - discriminator_yfake_loss: 0.0810 - discriminator_yreal_loss: 0.0879 - val_loss: 25.6122 - val_generator_loss: 14.9260 - val_generator_yfake_loss: 14.9224 - val_generator_yreal_loss: 0.0036 - val_discriminator_loss: 10.6862 - val_discriminator_yfake_loss: 1.5074e-06 - val_discriminator_yreal_loss: 10.6862\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 66s 1ms/step - loss: 10.3852 - generator_loss: 10.1806 - generator_yfake_loss: 4.6934 - generator_yreal_loss: 5.4872 - discriminator_loss: 0.2045 - discriminator_yfake_loss: 0.0966 - discriminator_yreal_loss: 0.1079 - val_loss: 17.9521 - val_generator_loss: 11.6779 - val_generator_yfake_loss: 0.0186 - val_generator_yreal_loss: 11.6593 - val_discriminator_loss: 6.2742 - val_discriminator_yfake_loss: 6.2738 - val_discriminator_yreal_loss: 4.4052e-04\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 66s 1ms/step - loss: 10.3387 - generator_loss: 10.1179 - generator_yfake_loss: 4.6555 - generator_yreal_loss: 5.4624 - discriminator_loss: 0.2208 - discriminator_yfake_loss: 0.1047 - discriminator_yreal_loss: 0.1161 - val_loss: 9.9171 - val_generator_loss: 9.0414 - val_generator_yfake_loss: 2.1368 - val_generator_yreal_loss: 6.9045 - val_discriminator_loss: 0.8757 - val_discriminator_yfake_loss: 0.7215 - val_discriminator_yreal_loss: 0.1542\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 66s 1ms/step - loss: 10.6084 - generator_loss: 10.4131 - generator_yfake_loss: 4.7518 - generator_yreal_loss: 5.6613 - discriminator_loss: 0.1953 - discriminator_yfake_loss: 0.0931 - discriminator_yreal_loss: 0.1022 - val_loss: 11.6667 - val_generator_loss: 9.1511 - val_generator_yfake_loss: 0.6435 - val_generator_yreal_loss: 8.5076 - val_discriminator_loss: 2.5156 - val_discriminator_yfake_loss: 2.4935 - val_discriminator_yreal_loss: 0.0220\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 66s 1ms/step - loss: 11.0366 - generator_loss: 10.8349 - generator_yfake_loss: 4.9949 - generator_yreal_loss: 5.8400 - discriminator_loss: 0.2017 - discriminator_yfake_loss: 0.0959 - discriminator_yreal_loss: 0.1058 - val_loss: 8.2806 - val_generator_loss: 7.7189 - val_generator_yfake_loss: 2.5369 - val_generator_yreal_loss: 5.1820 - val_discriminator_loss: 0.5617 - val_discriminator_yfake_loss: 0.3894 - val_discriminator_yreal_loss: 0.1723\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NoXLN0wX5oS1",
        "colab_type": "code",
        "outputId": "a9ecee5a-3655-49c4-d9fa-6af59f6678f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(history.history.keys())"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['val_loss', 'val_generator_loss', 'val_generator_yfake_loss', 'val_generator_yreal_loss', 'val_discriminator_loss', 'val_discriminator_yfake_loss', 'val_discriminator_yreal_loss', 'loss', 'generator_loss', 'generator_yfake_loss', 'generator_yreal_loss', 'discriminator_loss', 'discriminator_yfake_loss', 'discriminator_yreal_loss'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0QyVhAC5gJE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#save models' weights\n",
        "generator.save(\"output/gan_convolutional/generator.h5\")\n",
        "discriminator.save(\"output/gan_convolutional/discriminator.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zi9zI06EZw6E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}